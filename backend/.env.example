# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# Models
LLM_MODEL=qwen3:8b
EMBEDDING_MODEL=bge-m3

# ChromaDB
CHROMA_PERSIST_DIR=./chroma_db

# RAG
CHUNK_SIZE=1500
CHUNK_OVERLAP=150
RETRIEVER_K=6
LLM_TEMPERATURE=0.1

# API
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=["https://plataforma-libros.vercel.app","http://localhost:3000"]

# Documents
DOCS_DIR=./docs
