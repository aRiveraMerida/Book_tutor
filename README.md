# ğŸ“š BookTutor

**Plataforma educativa con tutor IA basado en RAG (Retrieval-Augmented Generation)**

BookTutor permite a los estudiantes leer documentos de estudio y hacer preguntas a un tutor IA que responde basÃ¡ndose exclusivamente en el contenido del material, citando las fuentes.

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Frontend     â”‚â”€â”€â”€â”€â–¶â”‚     Backend     â”‚â”€â”€â”€â”€â–¶â”‚     Ollama      â”‚
â”‚   (Next.js)     â”‚     â”‚   (FastAPI)     â”‚     â”‚   (LLM Local)   â”‚
â”‚   Puerto 3000   â”‚     â”‚   Puerto 8000   â”‚     â”‚  Puerto 11434   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     Qdrant      â”‚
                        â”‚ (Vector Store)  â”‚
                        â”‚   Puerto 6333   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack TecnolÃ³gico

| Componente | TecnologÃ­a | VersiÃ³n |
|------------|------------|---------|
| Frontend | Next.js + React | 15.x |
| Backend | FastAPI + Python | 3.12+ |
| LLM | Ollama (qwen3:8b) | Local |
| Embeddings | Ollama (bge-m3) | 1024 dims |
| Vector DB | Qdrant | 1.7.x |
| Auth | JWT (HS256) | - |

---

## ğŸ“ Estructura del Proyecto

```
Book_tutor/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/           # Endpoints REST
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py       # Login, JWT
â”‚   â”‚   â”‚   â”œâ”€â”€ asignaturas.py # CRUD asignaturas
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py       # RAG Q&A
â”‚   â”‚   â”‚   â””â”€â”€ health.py     # Health check
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py     # Settings (pydantic)
â”‚   â”‚   â”‚   â””â”€â”€ security.py   # JWT, passwords
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ qdrant.py     # Qdrant client
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py       # LLM abstract
â”‚   â”‚   â”‚   â””â”€â”€ ollama.py     # Ollama provider
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py    # Document splitting
â”‚   â”‚   â”‚   â””â”€â”€ rag_service.py # RAG orchestration
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI app
â”‚   â”œâ”€â”€ docs/                  # Documentos por asignatura
â”‚   â”‚   â””â”€â”€ {slug}/           # e.g., programacion/
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                   # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ asignatura/[subject]/[file]/
â”‚   â”‚   â”œâ”€â”€ admin/
â”‚   â”‚   â””â”€â”€ login/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â”œâ”€â”€ FloatingChat.tsx
â”‚   â”‚       â””â”€â”€ ChatPanel.tsx
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ api.ts            # API client
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â””â”€â”€ Dockerfile.frontend
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start.sh              # Dev startup
â”‚   â””â”€â”€ seed_data.py          # Data seeding
â”‚
â”œâ”€â”€ docker-compose.yml        # Desarrollo
â”œâ”€â”€ docker-compose.prod.yml   # ProducciÃ³n
â””â”€â”€ .env.example
```

---

## ğŸš€ Inicio RÃ¡pido (Desarrollo)

### Prerequisitos

- Python 3.12+
- Node.js 20+
- Docker y Docker Compose
- Ollama instalado localmente

### 1. Clonar y configurar

```bash
git clone <repo-url>
cd Book_tutor
cp .env.example .env
```

### 2. Iniciar servicios Docker

```bash
# Qdrant (vector database)
docker-compose up -d qdrant
```

### 3. Configurar Ollama

```bash
# Instalar modelos requeridos
ollama pull qwen3:8b      # Chat model (~5GB)
ollama pull bge-m3        # Embeddings (~1.5GB)
```

### 4. Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Iniciar servidor
uvicorn app.main:app --reload --port 8000
```

### 5. Frontend

```bash
cd frontend
npm install
npm run dev
```

### 6. Acceder

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000/docs
- **Qdrant UI**: http://localhost:6333/dashboard

### Credenciales Demo

| Usuario | ContraseÃ±a | Rol |
|---------|------------|-----|
| admin | admin123 | Admin |
| user | user123 | User |

---

## ğŸ“– Uso del Sistema

### Flujo del Usuario

1. **Login** â†’ AutenticaciÃ³n con JWT
2. **Seleccionar asignatura** â†’ Ver lista de documentos
3. **Leer documento** â†’ Markdown renderizado
4. **Chat con tutor** â†’ BotÃ³n flotante o `âŒ˜K`
5. **Hacer preguntas** â†’ Respuestas con citas `[1][2]`

### Flujo del Admin

1. **Login como admin**
2. **Panel Admin** â†’ `/admin`
3. **Crear asignatura** â†’ Nombre, slug, icono
4. **Subir documentos** â†’ Markdown
5. **Procesar** â†’ Chunking + Embeddings â†’ Qdrant

---

## ğŸ”Œ API Endpoints

### AutenticaciÃ³n

```
POST /api/v1/auth/login
Body: { "username": "user", "password": "user123" }
Response: { "access_token": "...", "token_type": "bearer", "role": "user" }
```

### Asignaturas

```
GET  /api/v1/asignaturas              # Listar todas
GET  /api/v1/asignaturas/{slug}       # Detalle + documentos
POST /api/v1/asignaturas              # Crear (admin)
POST /api/v1/asignaturas/{slug}/process # Procesar docs (admin)
```

### Chat RAG

```
POST /api/v1/chat/{slug}/ask
Headers: Authorization: Bearer <token>
Body: { "question": "Â¿QuÃ© es Python?" }
Response: {
  "answer": "Python es un lenguaje... [1]",
  "sources": [
    { "source_file": "01-intro.md", "seccion": "Â¿QuÃ© es Python?", "score": 0.85 }
  ],
  "model_used": "qwen3:8b"
}
```

### Health Check

```
GET /api/v1/health
Response: { "status": "ok", "ollama": { "status": "ok", "models": [...] } }
```

---

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```env
# Backend
SECRET_KEY=your-secret-key-here
ENVIRONMENT=dev
CORS_ORIGINS=["http://localhost:3000"]

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_LLM_MODEL=qwen3:8b
EMBEDDING_MODEL=bge-m3

# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION_PREFIX=book_

# RAG Settings
CHUNK_SIZE=500
CHUNK_OVERLAP=100
RETRIEVER_K=6
MIN_RELEVANCE_SCORE=0.4

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## ğŸ§ª Testing

```bash
# Backend
cd backend
pytest tests/ -v

# Frontend
cd frontend
npm run test
```

---

## ğŸ“š AÃ±adir Contenido

### Formato de Documentos

Los documentos deben estar en Markdown con estructura jerÃ¡rquica:

```markdown
# TÃ­tulo del Documento

## SecciÃ³n Principal

Contenido de la secciÃ³n...

### SubsecciÃ³n

MÃ¡s contenido...
```

### UbicaciÃ³n

```
backend/docs/{slug-asignatura}/
â”œâ”€â”€ 01-introduccion.md
â”œâ”€â”€ 02-conceptos-basicos.md
â””â”€â”€ 03-ejercicios.md
```

### Procesar Documentos

```bash
# Via API (admin)
curl -X POST "http://localhost:8000/api/v1/asignaturas/programacion/process" \
  -H "Authorization: Bearer <admin-token>"
```

---

## ğŸ› ï¸ Desarrollo

### Convenciones de CÃ³digo

- **Python**: PEP 8, type hints
- **TypeScript**: ESLint + Prettier
- **Commits**: Conventional Commits

### Estructura de Branches

```
main        # ProducciÃ³n estable
â”œâ”€â”€ develop # Desarrollo
â””â”€â”€ feature/xxx # Nuevas funcionalidades
```

### Pre-commit (recomendado)

```bash
# Backend
pip install black isort ruff
black app/
isort app/
ruff check app/

# Frontend
npm run lint
npm run format
```

---

## ğŸ¤ Contribuir

1. Fork del repositorio
2. Crear branch: `git checkout -b feature/nueva-funcionalidad`
3. Commit: `git commit -m "feat: descripciÃ³n"`
4. Push: `git push origin feature/nueva-funcionalidad`
5. Pull Request

---

## ğŸ“„ DocumentaciÃ³n Adicional

- [DEPLOY.md](./DEPLOY.md) - GuÃ­a de despliegue
- [COST.md](./COST.md) - AnÃ¡lisis de costes

---

## ğŸ“œ Licencia

MIT License - Ver [LICENSE](./LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¥ Equipo

Desarrollado por el equipo de FP Prometeo.
